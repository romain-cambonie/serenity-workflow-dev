# TODO Better performances to find with the --jobs pg argument to try out following the runner characteristics
# TODO Input matrix with table list ? Worth it ?
# https://www.postgresql.org/docs/current/app-pgrestore.html --jobs=number-of-jobs
name: zReusable Scalingo Postgresql Clone database from postgreurl
# Clone a database data from its fully qualified url

on:
  workflow_call:
    inputs:
      application-name:
        required: true
        type: string

    secrets:
      SCALINGO_API_TOKEN:
        required: true
      REMOTE_DATABASE_URL:
        required: true

jobs:
  # Doing it in two steps helped mitigate errors resulting from some extensions (for example postgis)
  # that sometimes do not dump restore schema and data in a working fashion resulting in TOC error
  dump-and-restore-remote-db-data:
    name: Dump and restore the production database to the feature app
    runs-on: ubuntu-latest
    container:
      image: rcambonie/scalingo-cli

    steps:
      - name: Login with api-token
        run: scalingo login --api-token=${{ secrets.SCALINGO_API_TOKEN }}

      # Dump and restoring in 3 waves because dump does not takes fk into account and I cannot give user Superuser privileges to disable constrains while restoring.
      # A competent DBA may have a better solution
      - name: Dump the remote database data and restore it to the local database 1/3.
        env:
          REMOTE_DATABASE_URL: ${{ secrets.REMOTE_DATABASE_URL }}
          DATABASE_VAR: "$DATABASE_URL"
        run: >
          scalingo --app ${{ inputs.application-name }} run bash -c "echo 'Installing pgsql-client' && 
          dbclient-fetcher pgsql && 
          echo 'Dumping data 1' && 
          pg_dump --data-only --format c --no-owner --no-privileges --no-comments -t 'public.agencies' -t 'public.conventions' -t 'public.outbox' -t 'public.api_consumers' -t 'public.establishments' -t 'public.form_establishments' -t 'public.immersion_offers' -t 'public.lbb_requests' -t 'public.outbox' -t 'public.searches_made' --dbname "REMOTE_DATABASE_URL" --file dump-data.pgsql && 
          echo 'Finished dumping data 1' && 
          pg_restore --data-only --verbose --no-owner --no-privileges --no-comments --dbname "$DATABASE_VAR" dump-data.pgsql"

      - name: Dump the remote database data and restore it to the local database 2/3.
        env:
          REMOTE_DATABASE_URL: ${{ secrets.REMOTE_DATABASE_URL }}
          DATABASE_VAR: "$DATABASE_URL"
        run: >
          scalingo --app ${{ inputs.application-name }} run bash -c "echo 'Installing pgsql-client' && 
          dbclient-fetcher pgsql && 
          echo 'Dumping data 2' && 
          pg_dump --data-only --format c --no-owner --no-privileges --no-comments -t 'public.outbox_publications' -t 'public.immersion_assessments' -t 'public.immersion_contacts' -t 'public.immersion_offers' -t 'public.partners_pe_connect' --dbname "REMOTE_DATABASE_URL" --file dump-data-2.pgsql
          echo 'Finished dumping data 2' && 
          pg_restore --data-only --verbose --no-owner --no-privileges --no-comments --dbname "$DATABASE_VAR" dump-data-2.pgsql"

      - name: Dump the remote database data and restore it to the local database 3/3.
        env:
          REMOTE_DATABASE_URL: ${{ secrets.REMOTE_DATABASE_URL }}
          DATABASE_VAR: "$DATABASE_URL"
        run: >
          scalingo --app ${{ inputs.application-name }} run bash -c "echo 'Installing pgsql-client' && 
          dbclient-fetcher pgsql && 
          echo 'Dumping data 3' && 
          pg_dump --data-only --format c --no-owner --no-privileges --no-comments -t 'public.outbox_failures' -t 'public.convention_external_ids' -t 'public.establishments__immersion_contacts'  --dbname "REMOTE_DATABASE_URL" --file dump-data-3.pgsql
          echo 'Finished dumping data 3' && 
          pg_restore --data-only --verbose --no-owner --no-privileges --no-comments --dbname "$DATABASE_VAR" dump-data-3.pgsql"
